# AFM Phase Separation Training Guide
**Anchored Flow Matching with Hierarchical Identity/Motion Learning**

## ğŸ¯ Philosophy: Phase Separation

AFM Phase Separationì€ ë¹„ë””ì˜¤ ìƒì„±ì˜ ë³µì¡ì„±ì„ ì¤„ì´ê¸° ìœ„í•´ **Identity(í˜•ì²´)**ì™€ **Motion(ì›€ì§ì„)**ì„ ê³„ì¸µì ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ í•™ìŠµí•˜ëŠ” í˜ì‹ ì ì¸ ì ‘ê·¼ë²•ì…ë‹ˆë‹¤.

### Two-Stage Learning Process

**Stage 1: Global Identity Formation** (`t âˆˆ [0.2, 1.0]`)
- **ëª©í‘œ**: ëª¨ë“  í”„ë ˆì„ì´ ê³µí†µëœ ì•µì»¤(Identity)ë¡œ ìˆ˜ë ´í•˜ëŠ” ë²•ì„ í•™ìŠµ
- **íŠ¹ì§•**: í”„ë ˆì„ ê°„ ì°¨ì´ë¥¼ ë¬´ì‹œí•˜ê³  ì˜¤ì§ í˜•ì²´ í˜•ì„±ì—ë§Œ ì§‘ì¤‘
- **ê¸°ê°„**: 0 ~ 10,000 steps

**Stage 2: Local Motion Refinement** (`t âˆˆ [0.0, 0.2]`)
- **ëª©í‘œ**: í˜•ì„±ëœ ì•µì»¤ì—ì„œ í”„ë ˆì„ë³„ ì›€ì§ì„ì„ ë¶„í™”ì‹œí‚¤ëŠ” ë²•ì„ í•™ìŠµ
- **íŠ¹ì§•**: 2.0x Motion Gainìœ¼ë¡œ ë¯¸ì„¸í•œ ë³€ìœ„ ì‹ í˜¸ ì¦í­
- **ê¸°ê°„**: 10,000+ steps

## ğŸš€ Quick Start

### 1. ì²˜ìŒë¶€í„° ì‹œì‘ (Stage 1 â†’ Stage 2)

```bash
# AFM Phase Separation ì „ì²´ í•™ìŠµ (20k steps)
PYTHONPATH=src CUDA_VISIBLE_DEVICES=1 python scripts/train_distributed.py configs/afm_phase_config.yaml --num_processes 1
```

### 2. 10k ì²´í¬í¬ì¸íŠ¸ì—ì„œ Stage 2ë§Œ ì‹œì‘

```yaml
# afm_phase_config.yaml ìˆ˜ì •
model:
  load_checkpoint: "outputs/ring_fm_lora_v1/checkpoint-10000"  # 10k ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ

afm_training:
  auto_transition_step: 0  # ì¦‰ì‹œ Stage 2 ì‹œì‘
```

```bash
PYTHONPATH=src CUDA_VISIBLE_DEVICES=1 python scripts/train_distributed.py configs/afm_phase_config.yaml --num_processes 1
```

### 3. ê¸°ì¡´ Unified ëª¨ë“œì™€ ë¹„êµ

```yaml
# ê¸°ì¡´ ë°©ì‹ (ring_lora_config.yaml)
afm_training:
  use_phase_separation: false  # Phase Separation ë¹„í™œì„±í™”

# Phase Separation ë°©ì‹ (afm_phase_config.yaml) 
afm_training:
  use_phase_separation: true   # Phase Separation í™œì„±í™”
```

## ğŸ“Š WandB ëª¨ë‹ˆí„°ë§ ì§€í‘œ

### Core AFM Metrics
- `afm/current_stage`: í˜„ì¬ í•™ìŠµ Stage (`global_identity` â†’ `local_motion`)
- `afm/motion_gain`: ì ìš©ëœ Motion Gain (Stage 1: 1.0x, Stage 2: 2.0x)
- `afm/stage_transition`: Stage ì „í™˜ ì´ë²¤íŠ¸ (1ì´ë©´ ì „í™˜ ë°œìƒ)

### Stage-Specific Loss Metrics
- `afm_loss/local_raw`: Local Phase ì›ì‹œ Loss
- `afm_loss/global_raw`: Global Phase ì›ì‹œ Loss  
- `afm_loss/active_loss`: í˜„ì¬ Stageì—ì„œ í™œì„±í™”ëœ Loss
- `afm_loss/stage_focus`: í˜„ì¬ Stage ì„¤ëª… (`Identity Formation` / `Motion Refinement`)

### Progress Tracking
- `afm/progress_to_transition`: Stage 1 â†’ Stage 2 ì „í™˜ê¹Œì§€ì˜ ì§„í–‰ë¥  (0.0 ~ 1.0)
- `afm/t_range_min`, `afm/t_range_max`: í˜„ì¬ Stageì˜ íƒ€ì„ìŠ¤í… ìƒ˜í”Œë§ ë²”ìœ„
- `afm/samples_in_range`: ìƒ˜í”Œë§ëœ íƒ€ì„ìŠ¤í…ì´ ì˜¬ë°”ë¥¸ ë²”ìœ„ì— ìˆëŠ” ë¹„ìœ¨

## ğŸ”§ Advanced Configuration

### Custom Stage Transition

```yaml
afm_training:
  auto_transition_step: 15000  # 15kì—ì„œ Stage ì „í™˜
  
  # Stage 1 ì»¤ìŠ¤í„°ë§ˆì´ì§•
  stage1_config:
    motion_gain: 1.2           # ì•½ê°„ì˜ Motion Gain
    loss_weights:
      local: 0.1               # ì†ŒëŸ‰ì˜ Local Loss ìœ ì§€
      global: 1.0
  
  # Stage 2 ì»¤ìŠ¤í„°ë§ˆì´ì§•  
  stage2_config:
    motion_gain: 3.0           # ë” ê°•í•œ Motion Gain
    loss_weights:
      local: 15.0              # ë” ê°•í•œ Local Loss
      global: 0.0
```

### Phase-Aware Validation

```yaml
validation:
  interval: 1000               # Stageë³„ ë” ìì£¼ ê²€ì¦
  prompts:
    - "A person walking in the park"      # Motionì´ ì¤‘ìš”í•œ í”„ë¡¬í”„íŠ¸
    - "A rotating mechanical gear"        # ëª…í™•í•œ ì›€ì§ì„ íŒ¨í„´
    - "Facial expression changes"         # ë¯¸ì„¸í•œ ë³€í™” ê°ì§€
```

## ğŸ§ª Expected Results

### Stage 1 (Identity Formation)
**ì„±ê³µ ì§€í‘œ**:
- `afm_loss/global_raw` ì§€ì†ì  ê°ì†Œ
- `afm_loss/local_raw` â‰ˆ 0 (Local Loss ì°¨ë‹¨ë¨)
- ìƒì„±ëœ ë¹„ë””ì˜¤: ëª¨ë“  í”„ë ˆì„ì´ ìœ ì‚¬í•œ í˜•ì²´ (ì •ì§€ ìƒíƒœ)

### Stage 2 (Motion Refinement)  
**ì„±ê³µ ì§€í‘œ**:
- `afm_loss/local_raw` ì§€ì†ì  ê°ì†Œ
- `afm_loss/global_raw` â‰ˆ 0 (Global Loss ì°¨ë‹¨ë¨)
- `afm/motion_gain`: 2.0 (Motion ì¦í­ í™œì„±í™”)
- ìƒì„±ëœ ë¹„ë””ì˜¤: Identity ìœ ì§€í•˜ë©° ìì—°ìŠ¤ëŸ¬ìš´ ì›€ì§ì„ ìƒì„±

### Temporal Collapse í•´ê²°
**Before**: `local_vs_global_ratio` â‰ˆ 0 (ì›€ì§ì„ ì—†ìŒ)
**After**: `local_vs_global_ratio` â‰¥ 0.5 (í™œë°œí•œ ì›€ì§ì„)

## ğŸ¬ Inference with Trained Model

AFM Phaseë¡œ í•™ìŠµëœ ëª¨ë¸ì€ ê¸°ì¡´ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ê³¼ ì™„ë²½ í˜¸í™˜ë©ë‹ˆë‹¤:

```python
from ltxv_trainer.ltxv_pipeline import LtxvPipeline

# Stage 2 ì™„ë£Œëœ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
pipeline = LtxvPipeline.from_pretrained("outputs/afm_phase_separation_v1/checkpoint-20000")

# ì¼ë°˜ì ì¸ ë¹„ë””ì˜¤ ìƒì„±
video = pipeline(
    prompt="A person walking through a bustling city street",
    num_frames=25,
    height=512, width=512,
    num_inference_steps=50
)
```

## ğŸ“ˆ Performance Tips

1. **GPU Memory**: Stage 2ëŠ” ë” ë§ì€ ê·¸ë¼ë””ì–¸íŠ¸ ê³„ì‚°ìœ¼ë¡œ ì¸í•´ ì•½ê°„ ë” ë§ì€ VRAM ì‚¬ìš©
2. **Learning Rate**: Stage 2ì—ì„œëŠ” Learning Rateë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¤„ì´ëŠ” ê²ƒì„ ê¶Œì¥
3. **Batch Size**: Phase Separationì€ ì‘ì€ ë°°ì¹˜ì—ì„œë„ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™
4. **Checkpointing**: ê° Stage ì™„ë£Œ í›„ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ì„ ê¶Œì¥

## âš ï¸ Troubleshooting

### Stage ì „í™˜ì´ ì•ˆ ë  ë•Œ
```yaml
# ìˆ˜ë™ ê°•ì œ ì „í™˜ (í˜„ì¬ëŠ” config ìˆ˜ì •ìœ¼ë¡œ ëŒ€ì²´)
afm_training:
  auto_transition_step: 1  # ì¦‰ì‹œ Stage 2ë¡œ ê°•ì œ ì „í™˜
```

### Motionì´ ì•½í•  ë•Œ
```yaml
# Motion Gain ì¦ê°€
stage2_config:
  motion_gain: 4.0  # ê¸°ë³¸ê°’ 2.0ì—ì„œ 4.0ìœ¼ë¡œ ì¦ê°€
```

### Identityê°€ ë¶ˆì•ˆì •í•  ë•Œ
```yaml
# Stage 1 ê¸°ê°„ ì—°ì¥
afm_training:
  auto_transition_step: 15000  # 10k â†’ 15kë¡œ ì—°ì¥
```

---

**ğŸ¯ AFM Phase Separationìœ¼ë¡œ ë¹„ë””ì˜¤ ìƒì„±ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ê²½í—˜í•´ë³´ì„¸ìš”!**