"""
AFM Phase-Aware Training Strategy
í†µí•©ëœ Phase Separation í•™ìŠµ ì „ëµ êµ¬í˜„
"""

import random
import torch
import wandb
from typing import Any
from pydantic import BaseModel

from ltxv_trainer import logger
from ltxv_trainer.config import ConditioningConfig
from ltxv_trainer.ltxv_utils import get_rope_scale_factors
from ltxv_trainer.timestep_samplers import TimestepSampler
from ltxv_trainer.training_strategies import TrainingBatch, TrainingStrategy

from .afm_phase_manager import AFMPhaseManager, AFMTrainingStage
from .afm_timestep_samplers import AFMPhaseSampler
from .ring_zipper_flow import FlowMatchingBase, create_flow_matching


class AFMTrainingBatch(TrainingBatch):
    """AFM ì „ìš© Training Batch - Phase ì •ë³´ ì¶”ê°€"""
    
    # ê¸°ì¡´ TrainingBatch í•„ë“œë“¤ ìƒì†
    afm_stage: AFMTrainingStage
    motion_gain: float
    stage_loss_weights: tuple[float, float]  # (local_weight, global_weight)
    
    model_config = {"arbitrary_types_allowed": True}


class AFMPhaseTrainingStrategy(TrainingStrategy):
    """
    AFM Phase-Aware Training Strategy
    
    Phase Managerì™€ ì—°ë™í•˜ì—¬ ìë™ìœ¼ë¡œ Stageë³„ í•™ìŠµ ì „ëµì„ ì ìš©
    - Stage 1: Global Identity Formation (t âˆˆ [0.2, 1.0])
    - Stage 2: Local Motion Refinement (t âˆˆ [0.0, 0.2])
    """
    
    def __init__(self, conditioning_config: ConditioningConfig, phase_manager: AFMPhaseManager):
        super().__init__(conditioning_config)
        self.phase_manager = phase_manager
        self.t_star = getattr(conditioning_config, 't_star', 0.2)
        
        # Flow Matching ì—”ì§„ ì´ˆê¸°í™”
        self.flow_matching = create_flow_matching(
            method="ring_fm",
            t_star=self.t_star,
            latent_dim=128
        )
        
        # Phase-Aware Timestep Sampler
        self.phase_sampler = AFMPhaseSampler(self.phase_manager)
        
        self.accelerator = None
        self.global_step = 0
        
        logger.info(f"ğŸ¯ AFM Phase Training Strategy initialized with t_star={self.t_star}")
    
    def update_step(self, step: int):
        """ìŠ¤í… ì—…ë°ì´íŠ¸ ë° Phase Manager ë™ê¸°í™”"""
        self.global_step = step
        stage_changed = self.phase_manager.update_step(step)
        
        if stage_changed:
            # Stage ì „í™˜ ì‹œ ì¶”ê°€ ë¡œì§ (í•„ìš”í•˜ë‹¤ë©´)
            current_stage = self.phase_manager.current_stage
            logger.info(f"ğŸ”„ Training strategy adapted to {current_stage.value}")
    
    def get_data_sources(self) -> list[str]:
        return ["latents", "conditions"]
    
    def prepare_batch(self, batch: dict[str, Any], timestep_sampler: TimestepSampler) -> AFMTrainingBatch:
        """Phase-Aware Batch ì¤€ë¹„"""
        
        # 1. ê¸°ë³¸ ë°ì´í„° ì¶”ì¶œ ë° ë³€í™˜
        latents_info = batch["latents"]
        x0_seq = latents_info["latents"]
        B, S, C = x0_seq.shape
        F, H, W = latents_info["num_frames"][0].item(), latents_info["height"][0].item(), latents_info["width"][0].item()
        
        x0 = x0_seq.view(B, F, H, W, C).permute(0, 4, 1, 2, 3).contiguous()
        device = x0.device
        
        # 2. Phase-Aware íƒ€ì„ìŠ¤í… ìƒ˜í”Œë§
        t = self.phase_sampler.sample_for(x0_seq).to(device)
        
        # 3. í˜„ì¬ Stage ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        current_stage = self.phase_manager.current_stage
        motion_gain = self.phase_manager.get_motion_gain()
        loss_weights = self.phase_manager.get_loss_weights()
        
        # 4. Stageë³„ ë¡œê¹…
        t_mean = t.mean().item()
        t_min, t_max = self.phase_manager.get_timestep_range()
        
        stage_log = {
            "afm/current_stage": current_stage.value,
            "afm/t_mean": t_mean,
            "afm/t_range_min": t_min,
            "afm/t_range_max": t_max,
            "afm/motion_gain": motion_gain,
            "afm/samples_in_range": ((t >= t_min) & (t <= t_max)).float().mean().item()
        }
        
        if wandb.run is not None:
            wandb.log(stage_log)
        
        # í„°ë¯¸ë„ ë¡œê¹… (ë§¤ 50ìŠ¤í…ë§ˆë‹¤)
        if self.global_step % 50 == 0:
            logger.info(
                f"[AFM Step {self.global_step}] Stage: {current_stage.value}, "
                f"t_range: [{t_min:.2f}, {t_max:.2f}], t_mean: {t_mean:.4f}, "
                f"motion_gain: {motion_gain:.1f}x"
            )
        
        # 5. [RAB] Sparse Anchor ìƒì„±
        anchor, anchor_mu, anchor_log_sigma2 = self.flow_matching.compute_anchor(x0)

        # 6. [RAB] Flow Matching ì—°ì‚° (Unified Bridge Path)
        noise = self.flow_matching.sample_noise(x0.shape).to(device)
        z_t_vid = self.flow_matching.compute_forward_path(noise, x0, t, anchor=anchor)

        # [RAB] Residual Velocity (simplified interface)
        u_t_vid = self.flow_matching.compute_teacher_velocity(noise, x0, t, anchor=anchor)

        # [RAB] Get diagnostic metrics
        rab_metrics = self.flow_matching.get_rab_metrics()

        # Legacy compatibility: store reference norm if needed
        if current_stage == AFMTrainingStage.GLOBAL_IDENTITY:
            u_flat = u_t_vid.reshape(B, -1)
            current_norm = torch.linalg.vector_norm(u_flat, ord=2, dim=1).mean().item()
            alpha = 0.99
            if hasattr(self, '_stage1_reference_norm'):
                self._stage1_reference_norm = alpha * self._stage1_reference_norm + (1 - alpha) * current_norm
            else:
                self._stage1_reference_norm = current_norm
        
        # 7. Sequence í˜•íƒœë¡œ ë³€í™˜ + [TEMPORAL CONTRAST INJECTION]
        z_t_seq = z_t_vid.permute(0, 2, 3, 4, 1).reshape(B, S, C)
        u_t_seq = u_t_vid.permute(0, 2, 3, 4, 1).reshape(B, S, C)
        
        # [TEMPORAL CONTRAST] Frame-wise Divergence Boost (5x Temporal Signal Amplification)
        # í”„ë ˆì„ë³„ë¡œ ì„œë¡œ ë‹¤ë¥¸ temporal signalì„ ê°•ì œë¡œ ì£¼ì…í•˜ì—¬ í‰ê· í™” ë°©ì§€
        frame_positions = torch.arange(F, device=device, dtype=torch.float32)  # [0, 1, 2, ..., F-1]
        frame_contrast = 5.0 * torch.sin(frame_positions * 3.14159 / (F-1))  # 5x amplified sinusoidal contrast
        
        # Apply frame-wise contrast to velocity targets (B, F, H, W, C) -> (B, S, C)
        u_t_contrast = u_t_vid.clone()
        for f in range(F):
            frame_scale = 1.0 + 0.3 * frame_contrast[f]  # Â±30% frame-wise variation
            u_t_contrast[:, :, f, :, :] = u_t_contrast[:, :, f, :, :] * frame_scale
        
        u_t_seq = u_t_contrast.permute(0, 2, 3, 4, 1).reshape(B, S, C)
        u_t_seq = torch.clamp(u_t_seq, min=-2.0, max=2.0)
        
        # 8. í…ìŠ¤íŠ¸ ì¡°ê±´ ì¤€ë¹„
        conditions = batch["conditions"]
        prompt_embeds = conditions["prompt_embeds"]
        prompt_attention_mask = conditions["prompt_attention_mask"]
        
        sampled_timestep_values = torch.round(t * 1000.0).long()
        timesteps = sampled_timestep_values.unsqueeze(1).expand(B, S)
        
        return AFMTrainingBatch(
            latents=z_t_seq,
            targets=u_t_seq,
            prompt_embeds=prompt_embeds,
            prompt_attention_mask=prompt_attention_mask,
            timesteps=timesteps,
            sigmas=t.view(-1, 1, 1),
            conditioning_mask=torch.zeros(B, S, dtype=torch.bool, device=device),
            num_frames=F, height=H, width=W,
            fps=latents_info.get("fps", [24])[0].item(),
            rope_interpolation_scale=get_rope_scale_factors(24),
            
            # AFM ì „ìš© í•„ë“œ
            afm_stage=current_stage,
            motion_gain=motion_gain,
            stage_loss_weights=loss_weights
        )
    
    def compute_loss(self, model_pred: torch.Tensor, batch: AFMTrainingBatch) -> torch.Tensor:
        """
        Phase-Aware Loss Computation
        Stageë³„ Loss ê°€ì¤‘ì¹˜ë¡œ Identity/Motion í•™ìŠµ ì œì–´
        """
        
        # 1. ê¸°ë³¸ MSE Loss
        loss = (model_pred - batch.targets).pow(2)
        
        # 2. í˜„ì¬ Stageì˜ Loss ê°€ì¤‘ì¹˜ ì ìš©
        local_weight, global_weight = batch.stage_loss_weights
        t_flat = batch.sigmas.squeeze()
        t_threshold = self.t_star
        
        # Stageë³„ Loss ë§ˆìŠ¤í‚¹
        mask_local = t_flat <= t_threshold
        mask_global = t_flat > t_threshold
        
        # Phase-Specific Loss Weighting
        if batch.afm_stage == AFMTrainingStage.GLOBAL_IDENTITY:
            # Stage 1: Global Lossë§Œ í™œì„±í™”, Local Loss ì°¨ë‹¨
            stage_weights = torch.where(mask_local, 0.0, global_weight)
            focus_description = "Identity Formation"
            
        elif batch.afm_stage == AFMTrainingStage.LOCAL_MOTION:
            # Stage 2: Local Lossë§Œ í™œì„±í™”, Global Loss ì°¨ë‹¨
            stage_weights = torch.where(mask_local, local_weight, 0.0)
            focus_description = "Motion Refinement"
            
        else:
            # Fallback: ê¸°ë³¸ ê°€ì¤‘ì¹˜
            stage_weights = torch.where(mask_local, local_weight, global_weight)
            focus_description = "Mixed Training"
        
        # 3. Dynamic Loss Scaling based on target_norm
        # Stageë³„ë¡œ target normì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì •ê·œí™”í•˜ì—¬ ê· í˜• ë§ì¶¤
        B = model_pred.shape[0]
        target_flat = batch.targets.reshape(B, -1)
        target_norm_per_sample = torch.linalg.vector_norm(target_flat, ord=2, dim=1)  # (B,)
        
        # ê° Stageë³„ target norm í†µê³„
        local_mask = mask_local
        global_mask = mask_global
        
        # Stageë³„ í‰ê·  target norm ê³„ì‚°
        if local_mask.any():
            local_target_norm_mean = target_norm_per_sample[local_mask].mean().item()
        else:
            local_target_norm_mean = 1.0
            
        if global_mask.any():
            global_target_norm_mean = target_norm_per_sample[global_mask].mean().item()
        else:
            global_target_norm_mean = 1.0
        
        # Dynamic Loss Scaling: target normì— ì—­ìˆ˜ë¥¼ ì·¨í•´ ì •ê·œí™”
        # ëª©í‘œ: ëª¨ë“  Stageì˜ lossê°€ ë¹„ìŠ·í•œ í¬ê¸°ë¥¼ ê°–ë„ë¡ ì¡°ì •
        reference_norm = max(local_target_norm_mean, global_target_norm_mean, 0.1)  # ì•ˆì •ì„±ì„ ìœ„í•œ ìµœì†Œê°’
        
        dynamic_local_scale = reference_norm / max(local_target_norm_mean, 0.1)
        dynamic_global_scale = reference_norm / max(global_target_norm_mean, 0.1)
        
        # Stageë³„ Dynamic Scaling ì ìš©
        dynamic_scale = torch.where(local_mask, dynamic_local_scale, dynamic_global_scale)
        
        # ìµœì¢… ê°€ì¤‘ì¹˜ = Stage Weight Ã— Dynamic Scale
        final_weights = stage_weights.unsqueeze(-1).unsqueeze(-1) * dynamic_scale.unsqueeze(-1).unsqueeze(-1)
        
        # 3. Loss ì ìš© (Dynamic Scaling í¬í•¨)
        weighted_loss = loss * final_weights
        base_loss = weighted_loss.mean()
        
        # [TEMPORAL DIVERSITY LOSS] Frame-wise Variance Penalty to Prevent Averaging
        temporal_diversity_penalty = 0.0
        if F > 1:  # Only apply if we have multiple frames
            # Reshape predictions per frame: (B, S, C) -> (B, F, spatial_tokens, C)
            spatial_tokens = S // F
            pred_per_frame = model_pred.reshape(B, F, spatial_tokens, model_pred.shape[-1])  # (B, F, spatial, C)
            
            # Compute frame-wise predictions (average across spatial)
            frame_preds = pred_per_frame.mean(dim=2)  # (B, F, C) - averaged prediction per frame
            
            # Frame-wise variance within each batch
            frame_variance = frame_preds.var(dim=1, unbiased=False).mean()  # Mean variance across frames and channels
            
            # Exponential penalty: force diversity, heavily penalize low variance
            # Î» = 2.0 (aggressive penalty), minimum variance = 0.01
            min_variance_threshold = 0.01
            diversity_lambda = 2.0
            temporal_diversity_penalty = diversity_lambda * torch.exp(-10.0 * torch.clamp(frame_variance, min=1e-8))
            
            # Add to loss
            final_loss = base_loss + temporal_diversity_penalty
        else:
            final_loss = base_loss
        
        # 4. ìƒì„¸ ë©”íŠ¸ë¦­ ê³„ì‚°
        pred_flat = model_pred.reshape(B, -1)
        target_flat = batch.targets.reshape(B, -1)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        import torch.nn.functional as F
        cosine_sim = F.cosine_similarity(pred_flat, target_flat, dim=1).mean().item()
        
        # L2 Norm with Predictive Norm Regularization
        target_norm_per_sample = torch.linalg.vector_norm(target_flat, ord=2, dim=1)
        pred_norm_per_sample = torch.linalg.vector_norm(pred_flat, ord=2, dim=1)
        
        target_norm = target_norm_per_sample.mean().item()
        pred_norm = pred_norm_per_sample.mean().item()
        
        # Advanced Pred-Norm Variance Regularization (Stage 2 only)
        pred_norm_variance = 0.0
        norm_variance_penalty = 0.0
        scale_regularization_penalty = 0.0
        current_stage = batch.afm_stage  # Get current stage from batch
        
        if current_stage == AFMTrainingStage.LOCAL_MOTION:
            # Debug variance calculation - ì‹¤ì œ pred_normì´ ìš”ë™ì¹˜ëŠ” ìƒí™©ì„ ì •í™•íˆ í¬ì°©
            if B > 1:
                pred_norm_variance = pred_norm_per_sample.var().item()
            else:
                # Single sampleì¼ ë•Œë„ ì´ì „ ë°°ì¹˜ë“¤ì˜ norm ê°’ê³¼ ë¹„êµí•˜ì—¬ variance ì¶”ì •
                # Maintain a rolling buffer of recent pred_norm values
                if not hasattr(self, '_norm_history_buffer'):
                    self._norm_history_buffer = []
                
                self._norm_history_buffer.append(pred_norm)
                # Keep last 10 values for variance estimation
                if len(self._norm_history_buffer) > 10:
                    self._norm_history_buffer.pop(0)
                
                # Calculate variance from historical buffer
                if len(self._norm_history_buffer) >= 3:
                    import statistics
                    pred_norm_variance = statistics.variance(self._norm_history_buffer)
                else:
                    # Not enough history - use magnitude-based variance proxy
                    expected_norm_center = 450.0  # Target stable norm
                    deviation = abs(pred_norm - expected_norm_center)
                    pred_norm_variance = deviation ** 2  # Squared deviation as variance proxy
            
            # Aggressive Scale Regularization: Manifold Forced Anchoring
            batch_mean_norm = pred_norm_per_sample.mean().item()
            if batch_mean_norm > 450.0:  # Aggressive threshold for texture preservation
                # Exponential penalty for strong enforcement
                overshoot = batch_mean_norm - 450.0
                scale_penalty_factor = 0.05  # Strong penalty factor
                scale_regularization_penalty = scale_penalty_factor * (overshoot ** 1.2)  # Superlinear growth
                final_loss = final_loss + scale_regularization_penalty
            
            # Variance penalty for high inter-sample variance
            if pred_norm_variance > 10000.0:  # Threshold for dangerous variance
                variance_penalty_factor = 0.002  # Conservative penalty
                norm_variance_penalty = variance_penalty_factor * pred_norm_variance
                final_loss = final_loss + norm_variance_penalty
        
        # Stageë³„ Loss ë¶„ì„
        loss_per_sample = loss.reshape(B, -1).mean(dim=1)
        
        local_loss_raw = loss_per_sample[mask_local].mean().item() if mask_local.any() else 0.0
        global_loss_raw = loss_per_sample[mask_global].mean().item() if mask_global.any() else 0.0
        
        # í™œì„± Loss (ê°€ì¤‘ì¹˜ ì ìš© í›„)
        weighted_loss_per_sample = weighted_loss.reshape(B, -1).mean(dim=1)
        active_loss = weighted_loss_per_sample[weighted_loss_per_sample > 0].mean().item() if (weighted_loss_per_sample > 0).any() else 0.0
        
        # 5. AFM ì „ìš© ë©”íŠ¸ë¦­ ë¡œê¹… (SNR + Dynamic Scaling í¬í•¨)
        
        # SNR ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        snr_metrics = self.flow_matching.get_snr_metrics()
        
        # Hybrid Sampling í†µê³„ (ë§Œì•½ ì‚¬ìš© ì¤‘ì´ë¼ë©´)
        if hasattr(self.phase_sampler, 'get_sampling_stats'):
            sampling_stats = self.phase_sampler.get_sampling_stats(t_flat)
        else:
            sampling_stats = {}
        
        afm_metrics = {
            # ê¸°ë³¸ ë©”íŠ¸ë¦­
            "loss/cosine_similarity": cosine_sim,
            "loss/target_norm": target_norm,
            "loss/pred_norm": pred_norm,
            
            # Stage-Specific Metrics
            f"afm_loss/local_raw": local_loss_raw,
            f"afm_loss/global_raw": global_loss_raw,
            f"afm_loss/active_loss": active_loss,
            f"afm_loss/stage_focus": focus_description,
            
            # Phase Progress
            "afm_loss/local_samples_ratio": mask_local.float().mean().item(),
            "afm_loss/motion_gain_applied": batch.motion_gain,
            
            # Temporal Diversity Metrics (Averaging Collapse Prevention)
            "afm_temporal/diversity_penalty": temporal_diversity_penalty.item() if isinstance(temporal_diversity_penalty, torch.Tensor) else temporal_diversity_penalty,
            "afm_temporal/frame_variance": frame_variance.item() if F > 1 and 'frame_variance' in locals() else 0.0,
            
            # Dynamic Loss Scaling Metrics
            "afm_snr/local_target_norm": local_target_norm_mean,
            "afm_snr/global_target_norm": global_target_norm_mean,
            "afm_snr/dynamic_local_scale": dynamic_local_scale,
            "afm_snr/dynamic_global_scale": dynamic_global_scale,
            "afm_snr/reference_norm": reference_norm,
            
            # Stage 1 ê¸°ì¤€ norm (SNR Rescaling)
            "afm_snr/stage1_reference_norm": getattr(self, '_stage1_reference_norm', 1.0),
            
            # Advanced Predictive Norm Regularization
            "afm_stability/pred_norm_variance": pred_norm_variance,
            "afm_stability/norm_variance_penalty": norm_variance_penalty,
            "afm_stability/scale_regularization_penalty": scale_regularization_penalty,
            "afm_stability/batch_mean_norm": pred_norm_per_sample.mean().item() if current_stage == AFMTrainingStage.LOCAL_MOTION else 0.0,
        }
        
        # SNR ë©”íŠ¸ë¦­ ì¶”ê°€
        for key, value in snr_metrics.items():
            afm_metrics[f"afm_snr/{key}"] = value
            
        # Sampling í†µê³„ ì¶”ê°€
        for key, value in sampling_stats.items():
            afm_metrics[f"afm_sampling/{key}"] = value
        
        # Phase Manager ë©”íŠ¸ë¦­ ê²°í•©
        afm_metrics.update(self.phase_manager.get_stage_metrics())
        
        if wandb.run is not None:
            wandb.log(afm_metrics)
        
        # í„°ë¯¸ë„ ë¡œê¹… (ë§¤ 50ìŠ¤í…ë§ˆë‹¤)
        if self.global_step % 50 == 0:
            stability_info = ""
            if current_stage == AFMTrainingStage.LOCAL_MOTION:
                stability_info = f", Pred_Var: {pred_norm_variance:.1f}"
                if scale_regularization_penalty > 0:
                    stability_info += f", Scale_Penalty: {scale_regularization_penalty:.4f}"
                if norm_variance_penalty > 0:
                    stability_info += f", Var_Penalty: {norm_variance_penalty:.4f}"
            
            logger.info(
                f"[AFM Loss Step {self.global_step}] Stage: {batch.afm_stage.value} ({focus_description})\n"
                f"  Similarity: cosine={cosine_sim:.4f}, target_norm={target_norm:.4f}, pred_norm={pred_norm:.4f}{stability_info}\n"
                f"  Raw Loss - Local: {local_loss_raw:.4f}, Global: {global_loss_raw:.4f}\n"
                f"  Active Loss: {active_loss:.4f}, Motion Gain: {batch.motion_gain:.1f}x"
            )
        
        return final_loss


def create_afm_training_strategy(conditioning_config: ConditioningConfig, 
                                current_step: int = 0, 
                                auto_transition_step: int = 10000) -> AFMPhaseTrainingStrategy:
    """
    AFM Training Strategy Factory
    
    Args:
        conditioning_config: ì¡°ê±´ë¶€ í•™ìŠµ ì„¤ì •
        current_step: í˜„ì¬ ìŠ¤í… (ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹œ)
        auto_transition_step: ìë™ Stage ì „í™˜ ìŠ¤í…
    """
    
    # Phase Manager ì´ˆê¸°í™”
    phase_manager = AFMPhaseManager(
        current_step=current_step,
        auto_transition_step=auto_transition_step
    )
    
    # Training Strategy ìƒì„±
    strategy = AFMPhaseTrainingStrategy(conditioning_config, phase_manager)
    strategy.global_step = current_step
    
    logger.info(
        f"âœ… AFM Phase Training Strategy created - "
        f"Current Stage: {phase_manager.current_stage.value}, Step: {current_step}"
    )
    
    return strategy